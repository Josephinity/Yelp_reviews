{
 "metadata": {
  "name": "",
  "signature": "sha256:8bd5b9475cacf908cf9fb5b353250e0bc012fb6342436afd984b82484c58f3e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd~/GitHub/Yelp_reviews\n",
      "execfile('read_reviews_txt.py')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/xiaobaby/GitHub/Yelp_reviews\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviews=read_reviews_txt('reviews_0_50.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(reviews)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "21675"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot distribution for pandas data\n",
      "pd.options.display.mpl_style = 'default'\n",
      "reviews.review_rating.astype(float).hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x10dd22050>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEBCAYAAACe6Rn8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10dd49090>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#review tokenizer(& punctuation stripper)\n",
      "punctuations = set(['[','!','#','\"','%','&','\\\\','(',')','*'\n",
      "                    ,'+',',','-','.','/',':',';','<','=','>','?','@','[',']','^','_','`','{','|','}','~',']'])\n",
      "strip_punctuations = lambda x: ''.join([i if i not in punctuations else ' ' for i in x ])\n",
      "reviews['words']=[strip_punctuations(r.lower()).split() for r in reviews.review]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 313
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reviews.words[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'the', u'short', u'i', u'love', u'this', u'place', u\"i'm\", u'salivating', u'while', u'writing', u'this', u'review', u'ambiance', u'very', u'nice', u'options', u'to', u'sit', u'on', u'tatami', u'mat', u'with', u'feet', u'on', u'the', u'ground', u'need', u'to', u'take', u'shoes', u'off', u'at', u'a', u'regular', u'table', u'at', u'a', u'mini', u'counter', u'bar', u'or', u'a', u'screened', u'area', u'on', u'the', u'two', u'occasions', u'that', u\"i've\", u'been', u'to', u'gochi', u\"i've\", u'overheard', u'japanese', u'people', u'talking', u'i', u'love', u'it', u'because', u\"that's\", u'always', u'a', u'sign', u'that', u'they', u'equally', u'think', u'the', u'food', u'is', u'authentic', u'and', u'delicious', u'service', u'phenomenal', u'all', u'the', u'waiters', u'are', u'very', u'kind', u'very', u'patient', u'and', u'very', u'attentive', u'they', u'were', u'never', u'gone', u'for', u'too', u'long', u'nor', u'were', u'they', u'breathing', u'down', u'our', u'backs', u'food', u'amazing', u'really', u'fresh', u'and', u'the', u'food', u'has', u'a', u'lot', u'of', u'unique', u'flavors', u'that', u'are', u'very', u'rare', u'in', u'other', u'japanese', u'restaurants', u'i', u'thought', u'i', u'had', u'written', u'down', u'everything', u'we', u'had', u'ordered', u'but', u'i', u'lost', u'it', u'i', u'do', u'remember', u'that', u'the', u'unagi', u'pizza', u'was', u'a', u'very', u'memorable', u'dish', u'there', u'was', u'no', u'dish', u'that', u'i', u\"didn't\", u'like', u'in', u'fact', u'there', u'were', u'many', u'dishes', u'that', u'i', u'loved', u\"there's\", u'a', u'paper', u'menu', u'with', u'daily', u'specials', u'and', u'a', u'regular', u'menu', u'with', u'everyday', u'food', u\"there's\", u'also', u'a', u'glutenfree', u'menu', u'thanks', u'gochi', u'for', u'the', u'memorable', u'experience', u'i', u'hope', u'to', u'frequent', u'you', u'more', u'often', u'tip', u'make', u'a', u'reservation']\n"
       ]
      }
     ],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#apply naive bayes classifier\n",
      "import collections, itertools\n",
      "import nltk.classify.util, nltk.metrics\n",
      "from nltk.classify import NaiveBayesClassifier\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.collocations import *\n",
      "from nltk.metrics import BigramAssocMeasures,scores\n",
      "from nltk.probability import FreqDist, ConditionalFreqDist\n",
      "\n",
      "\n",
      "#create bag of words\n",
      "def all_words(data):\n",
      "    dic={}\n",
      "    for label in data.keys():\n",
      "        tokens = []\n",
      "        for words in data[label]:\n",
      "            tokens += words\n",
      "        dic[label] = tokens\n",
      "    return dic\n",
      "\n",
      "\n",
      "#initial run, include all words in analysis\n",
      "def word_feats(words):\n",
      "    return dict([(word.lower(), True) for word in words])    \n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#identify significant features                      ----nBestWords N, minFreq\n",
      "def get_nBestFeatures(labeled_words, N = 50):\n",
      "    word_fd = FreqDist()\n",
      "    label_word_fd = ConditionalFreqDist()\n",
      "    \n",
      "    #word count\n",
      "    word_count = {'total':0}\n",
      "    \n",
      "    for label in labeled_words.keys():\n",
      "        for word in labeled_words[label]:\n",
      "            word_fd[word.lower()]+=1\n",
      "            label_word_fd[label][word.lower()]+=1\n",
      "        word_count[label] = label_word_fd[label].N()\n",
      "        word_count['total'] += word_count[label]\n",
      "    \n",
      "    word_scores = {}\n",
      "    \n",
      "    for word, freq in word_fd.iteritems():\n",
      "        word_scores[word] = 0\n",
      "        for label in labeled_words.keys():\n",
      "            word_scores[word] += BigramAssocMeasures.chi_sq(label_word_fd[label][word],\n",
      "                (freq, word_count[label]), word_count['total'])            \n",
      "            \n",
      "    best = sorted(word_scores.iteritems(), key=lambda (w,s): s, reverse=True)[:N]\n",
      "    bestwords = set([w for w, s in best if word_fd[w]>=minFreq])\n",
      "    return bestwords\n",
      "\n",
      "#second run, include only nBestWords    \n",
      "def best_word_feats(words,bestwords):\n",
      "    return dict([(word, True) for word in words if word in bestwords])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#identify n-grams       ---minFreq, nBestNGrams , n best ngram features\n",
      "def find_ngrams(data):\n",
      "    volcabulary = []\n",
      "    for sublist in all_words(data).values():\n",
      "        volcabulary += sublist\n",
      "        \n",
      "    bigram_finder = BigramCollocationFinder.from_words(volcabulary)\n",
      "    bigram_finder.apply_freq_filter(minFreq)\n",
      "    bigrams = bigram_finder.nbest(BigramAssocMeasures.pmi, 200)\n",
      "    trigram_finder = TrigramCollocationFinder.from_words(volcabulary)\n",
      "    trigram_finder.apply_freq_filter(minFreq-2)\n",
      "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
      "    trigrams = trigram_finder.nbest(trigram_measures.pmi, 200)\n",
      "    return bigrams+trigrams\n",
      " \n",
      "#final run, include n-grams     \n",
      "def best_ngram_word_feats(words, ngrams, bestwords, score_fn=BigramAssocMeasures.chi_sq):\n",
      "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
      "    bigrams_ = bigram_finder.nbest(BigramAssocMeasures.pmi, nBestNGrams)\n",
      "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
      "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
      "    trigrams_ = trigram_finder.nbest(trigram_measures.pmi, nBestNGrams)\n",
      "    d = dict([(ngram, True) for ngram in bigrams_+trigrams_ if ngram in ngrams])\n",
      "    d.update(best_word_feats(words,bestwords))\n",
      "    return d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_classifier(data,featx):\n",
      "    \n",
      "    bestwords = get_nBestFeatures(all_words(data),N=nBestFeatures)\n",
      "    if best_word_feats==featx:\n",
      "        features = {label:[(featx(words,bestwords),label) for words in data[label]] for label in data.keys()}\n",
      "    elif best_ngram_word_feats==featx:\n",
      "        ngrams = find_ngrams(data)\n",
      "        features = {label:[(featx(words,ngrams,bestwords),label) for words in data[label]] for label in data.keys()}\n",
      "    else:\n",
      "        features={label:[(featx(words),label) for words in data[label]] for label in data.keys()}\n",
      "    \n",
      "    for label in features.keys():\n",
      "        print (label + 'sample = %i' %len(features[label]))\n",
      "        \n",
      "    trainfeats = []\n",
      "    testfeats = []\n",
      "    for label in features.keys():\n",
      "        trainfeats += features[label][:len(features[label])*3/4] #decide size of train/test cutoff here\n",
      "        testfeats += features[label][len(features[label])*3/4:]\n",
      "        \n",
      "    print 'training size:  %i, testing size: %i' %(len(trainfeats),len(testfeats))\n",
      " \n",
      "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
      "    refsets = collections.defaultdict(set)  \n",
      "    testsets = collections.defaultdict(set)   \n",
      " \n",
      "    for i, (feats, label) in enumerate(testfeats):\n",
      "            refsets[label].add(i)\n",
      "            observed = classifier.classify(feats)\n",
      "            testsets[observed].add(i)\n",
      " \n",
      "    print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
      "    #return nltk.classify.util.accuracy(classifier, testfeats)\n",
      "    if(len(features)==2):\n",
      "        print 'pos precision:', scores.precision(refsets['pos'], testsets['pos'])\n",
      "        print 'pos recall:', scores.recall(refsets['pos'], testsets['pos'])\n",
      "        print 'neg precision:', scores.precision(refsets['neg'], testsets['neg'])\n",
      "        print 'neg recall:', scores.recall(refsets['neg'], testsets['neg'])\n",
      "    classifier.show_most_informative_features(n=15)\n",
      "    #return (nltk.classify.util.accuracy(classifier, testfeats),scores.recall(refsets['pos'], testsets['pos']))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_documents = reviews.words[reviews.review_rating.astype(float)>4.5]\n",
      "b_documents = reviews.words[reviews.review_rating.astype(float)==4]\n",
      "c_documents = reviews.words[reviews.review_rating.astype(float)==3]\n",
      "d_documents = reviews.words[reviews.review_rating.astype(float)<2.5]\n",
      "data = {\n",
      "        '5':a_documents,\n",
      "        '4':b_documents,\n",
      "        '3':c_documents,\n",
      "        '2':d_documents\n",
      "        }\n",
      "\n",
      "\n",
      "#only take the top nBest important features of all into account\n",
      "nBestFeatures=50\n",
      "#ignore words with <minFreq\n",
      "minFreq=50\n",
      "#top n ngrams for EACH review\n",
      "nBestNGrams=50\n",
      "\n",
      "\n",
      "#print 'evaluating single word features'\n",
      "#evaluate_classifier(data,word_feats)\n",
      "\n",
      "\n",
      " \n",
      "print 'evaluating best word features'\n",
      "evaluate_classifier(data,best_word_feats)\n",
      "\n",
      "\n",
      " \n",
      "print 'evaluating best words + bigram chi_sq word features'\n",
      "evaluate_classifier(data,best_ngram_word_feats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "evaluating best word features\n",
        "3sample = 3005"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2sample = 2367\n",
        "5sample = 8724\n",
        "4sample = 7579\n",
        "training size:  16255, testing size: 5420\n",
        "accuracy:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.503505535055\n",
        "Most Informative Features\n",
        "                   worst = True                2 : 5      =     84.1 : 1.0\n",
        "                terrible = True                2 : 5      =     32.7 : 1.0\n",
        "                horrible = True                2 : 5      =     28.4 : 1.0\n",
        "                    rude = True                2 : 5      =     20.2 : 1.0\n",
        "           disappointing = True                2 : 5      =     19.0 : 1.0\n",
        "                mediocre = True                2 : 5      =     18.4 : 1.0\n",
        "                    okay = True                3 : 5      =      9.1 : 1.0\n",
        "                 average = True                3 : 5      =      8.9 : 1.0\n",
        "                 manager = True                2 : 4      =      8.4 : 1.0\n",
        "                  decent = True                3 : 5      =      7.2 : 1.0\n",
        "                 amazing = True                5 : 2      =      6.4 : 1.0\n",
        "                      ok = True                3 : 5      =      5.9 : 1.0\n",
        "                   asked = True                2 : 5      =      5.7 : 1.0\n",
        "                 minutes = True                2 : 5      =      5.5 : 1.0\n",
        "               delicious = True                5 : 2      =      5.5 : 1.0\n",
        "evaluating best words + bigram chi_sq word features\n",
        "3sample = 3005"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2sample = 2367\n",
        "5sample = 8724\n",
        "4sample = 7579\n",
        "training size:  16255, testing size: 5420\n",
        "accuracy:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.514760147601\n",
        "Most Informative Features\n",
        "                   worst = True                2 : 5      =     84.1 : 1.0\n",
        "                terrible = True                2 : 5      =     32.7 : 1.0\n",
        "       (u'35', u'stars') = True                3 : 2      =     28.6 : 1.0\n",
        "                horrible = True                2 : 5      =     28.4 : 1.0\n",
        "   (u'took', u'forever') = True                3 : 5      =     24.2 : 1.0\n",
        "(u'will', u'definitely', u'be') = True                5 : 3      =     23.3 : 1.0\n",
        "(u'nothing', u'to', u'write') = True                3 : 5      =     20.3 : 1.0\n",
        "                    rude = True                2 : 5      =     20.2 : 1.0\n",
        "           disappointing = True                2 : 5      =     19.0 : 1.0\n",
        "                mediocre = True                2 : 5      =     18.4 : 1.0\n",
        "     (u'hands', u'down') = True                5 : 2      =     17.4 : 1.0\n",
        "      (u'flag', u'down') = True                3 : 5      =     16.8 : 1.0\n",
        "(u'highly', u'recommend') = True                5 : 2      =     16.7 : 1.0\n",
        "(u'green', u'tea', u'creme') = True                4 : 2      =     16.1 : 1.0\n",
        "(u'i', u'highly', u'recommend') = True                5 : 2      =     15.7 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positive_docs=[' '.join(words) for words in reviews.words[reviews.review_rating.astype(float)==5]]\n",
      "negative_docs=[' '.join(words) for words in reviews.words[reviews.review_rating.astype(float)<2.5]]\n",
      "y=['pos']*len(positive_docs)+['neg']*len(negative_docs)\n",
      "train_x = positive_docs[:len(positive_docs)*3/4]+negative_docs[:len(negative_docs)*3/4]\n",
      "train_y = ['pos']*(len(positive_docs)*3/4)+['neg']*(len(negative_docs)*3/4)\n",
      "test_x = positive_docs[len(positive_docs)*3/4:]+negative_docs[len(negative_docs)*3/4:]\n",
      "test_y = ['pos']*(len(positive_docs)-len(positive_docs)*3/4)+['neg']*(len(negative_docs)-len(negative_docs)*3/4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer()\n",
      "X_train_features = vectorizer.fit_transform(train_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 337
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "NBclf = MultinomialNB()\n",
      "model = NBclf.fit_transform(positive_docs+negative_docs,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(vectorizer.get_feature_names())\n",
      "X_train_features.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18685\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 342,
       "text": [
        "(8318, 18685)"
       ]
      }
     ],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "ch2 = SelectKBest(chi2, k = 5000)\n",
      "K_best = ch2.fit_transform(X_train_features, train_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.asarray(vectorizer.get_feature_names())[ch2.get_support()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'00' u'007' u'008' ..., u'zhajiangmian' u'zuma' u'zzzzzzzzz']\n"
       ]
      }
     ],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in reviews.index[reviews.review_rating.astype(float)==5]:\n",
      "    if 'addictingto' in reviews.words[i]:\n",
      "        print reviews.loc[i].review\n",
      "        print reviews.loc[i].words\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviews.words[6568]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 315,
       "text": [
        "[u'i',\n",
        " u'think',\n",
        " u'their',\n",
        " u'soup',\n",
        " u'bases',\n",
        " u'are',\n",
        " u'quite',\n",
        " u'unique',\n",
        " u'and',\n",
        " u'the',\n",
        " u'soy',\n",
        " u'milk',\n",
        " u'and',\n",
        " u'spicy',\n",
        " u'kimchi',\n",
        " u'ones',\n",
        " u'are',\n",
        " u'especially',\n",
        " u'addicting',\n",
        " u'to',\n",
        " u'me']"
       ]
      }
     ],
     "prompt_number": 315
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "12.9+12.9+3.3+9.9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 352,
       "text": [
        "39.0"
       ]
      }
     ],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "39/10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 353,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 353
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "144*.75\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 354,
       "text": [
        "108.0"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}